{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U.S. Bureau of Labor Statistics - CPI Analysis\n",
    "#### Eric Bottinelli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retrieve data via BLS API v2\n",
    "\n",
    "**Documentation**\n",
    "\n",
    "- https://www.bls.gov/developers/api_python.htm\n",
    "- https://data.bls.gov/cgi-bin/surveymost?cu\n",
    "- https://data.bls.gov/dataQuery/find?fq=survey:[cu]&s=popularity:D&r=100&st=0\n",
    "- https://www.bls.gov/cpi/tables/relative-importance/2023.htm\n",
    "\n",
    "**Packages to install**\n",
    "\n",
    "- Prettytable ('pip install prettytable')\n",
    "\n",
    "**API Series ID**\n",
    "\n",
    "Consumer Price Index for All Urban Consumers (CPI-U)\n",
    "- *All items in U.S. city average, all urban consumers*\n",
    "    - NSA: CUUR0000SA0\n",
    "    - SA: CUSR0000SA0\n",
    "- *All items less food and energy in U.S. city average, all urban consumers*\n",
    "    - NSA: CUUR0000SA0L1E\n",
    "    - SA: CUSR0000SA0L1E\n",
    "- *Food in U.S. city average, all urban consumers*\n",
    "    - NSA: CUUR0000SAF1\n",
    "    - SA: CUSR0000SAF1\n",
    "- *Food at home in U.S. city average, all urban consumers*\n",
    "    - NSA: CUUR0000SAF11\n",
    "    - SA: CUSR0000SAF11\n",
    "- *Energy in U.S. city average, all urban consumers*\n",
    "    - NSA: CUUR0000SA0E\n",
    "    - SA: CUSR0000SA0E\n",
    "- *Commodities less food and energy commodities in U.S. city average, all urban consumers*\n",
    "    - NSA: CUUR0000SACL1E\n",
    "    - SA: CUSR0000SACL1E4\n",
    "- *Services less energy services in U.S. city average, all urban consumers*\n",
    "    - NSA: CUUR0000SASLE\n",
    "    - SA: CUSR0000SASLE\n",
    "- *Shelter in U.S. city average, all urban consumers*\n",
    "    - NSA: CUUR0000SAH1\n",
    "    - SA: CUSR0000SAH1\n",
    "((https://www.bls.gov/cpi/factsheets/owners-equivalent-rent-and-rent.htm))\n",
    "\n",
    "**Calculate special CPI**\n",
    "\n",
    "Occasionally, a user wishes to estimate a price change that is not published by BLS. For instance, suppose a user would like a CPI series for ‘services less energy services and shelter’. This can be done by estimating a special index, in this case, ‘services less energy services and shelter’.\n",
    "[BLS Doc](https://www.bls.gov/cpi/factsheets/constructing-special-cpis.htm)\n",
    "\n",
    "If SEEB01 -> CUUR0000SEEB01\n",
    "\n",
    "Cost weight is just a sum of all the items\n",
    "\n",
    "If I add all the values to calculate the services less energy services and shelter, it becomes a lot of data. Explore different solution (e.g. remove goods from core CPI)\n",
    "\n",
    "**Supercore CPI**\n",
    "\n",
    "\"Fed Chair Jerome Powell cited a specific category of inflation—inflation in core services other than housing—as being perhaps “the most important category for understanding the future evolution of core inflation.” The financial press has termed this category “supercore” inflation\" ([FED of St. Louis](https://www.stlouisfed.org/on-the-economy/2024/may/measuring-inflation-headline-core-supercore-services))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import prettytable\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "folder_name = 'CPI_Data'\n",
    "\n",
    "food_weight = 13.555\n",
    "energy_weight = 6.655\n",
    "services_less_energy_weight = 60.899\n",
    "shelter_weight = 36.191\n",
    "\n",
    "weight_map = {\n",
    "    'All_Items': 100,\n",
    "    'Food_Energy': food_weight + energy_weight,\n",
    "    'Food': food_weight,\n",
    "    'Food_At_Home': 8.167,\n",
    "    'Food_Away_From_Home': 5.388,\n",
    "    'Energy': energy_weight,\n",
    "    'All_Items_Less_Food_Energy': 79.790,\n",
    "    'Commodities_Less_Food_Energy_Commodities': 18.891,\n",
    "    'Services_Less_Energy_Services': services_less_energy_weight,\n",
    "    'Shelter': shelter_weight,\n",
    "    'Supercore': services_less_energy_weight - shelter_weight \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "current_date = datetime.now()\n",
    "current_year = current_date.year\n",
    "last_year = current_year - 1\n",
    "\n",
    "series_names = {\n",
    "    'CUUR0000SA0': 'NSA_All_Items',\n",
    "    'CUSR0000SA0': 'SA_All_Items',\n",
    "    'CUUR0000SA0L1E': 'NSA_All_Items_Less_Food_Energy',\n",
    "    'CUSR0000SA0L1E': 'SA_All_Items_Less_Food_Energy',\n",
    "    'CUUR0000SAF': 'NSA_Food',\n",
    "    'CUSR0000SAF': 'SA_Food',\n",
    "    'CUUR0000SAF11': 'NSA_Food_At_Home',\n",
    "    'CUSR0000SAF11': 'SA_Food_At_Home',\n",
    "    'CUUR0000SEFV': 'NSA_Food_Away_From_Home',\n",
    "    'CUSR0000SEFV': 'SA_Food_Away_From_Home',\n",
    "    'CUUR0000SA0E': 'NSA_Energy',\n",
    "    'CUSR0000SA0E': 'SA_Energy',\n",
    "    'CUUR0000SACL1E': 'NSA_Commodities_Less_Food_Energy_Commodities',\n",
    "    'CUSR0000SACL1E4': 'SA_Commodities_Less_Food_Energy_Commodities',\n",
    "    'CUUR0000SASLE': 'NSA_Services_Less_Energy_Services',\n",
    "    'CUSR0000SASLE': 'SA_Services_Less_Energy_Services',\n",
    "    'CUUR0000SAH1': 'NSA_Shelter',\n",
    "    'CUSR0000SAH1': 'SA_Shelter',\n",
    "}\n",
    "series_ids = list(series_names.keys())\n",
    "\n",
    "headers = {'Content-type': 'application/json'}\n",
    "data = json.dumps({\"seriesid\": series_ids, \"startyear\": str(last_year), \"endyear\": str(current_year)})\n",
    "response = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=data, headers=headers)\n",
    "json_data = json.loads(response.text)\n",
    "\n",
    "all_data = []\n",
    "for series in json_data['Results']['series']:\n",
    "    rows = []\n",
    "    for item in series['data']:\n",
    "        footnotes = \"\".join([footnote['text'] + ',' for footnote in item['footnotes'] if footnote]).rstrip(',')\n",
    "        if 'M01' <= item['period'] <= 'M12':\n",
    "            rows.append([series_names[series['seriesID']], item['year'], item['period'], item['value'], footnotes])\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"series id\", \"year\", \"period\", \"value\", \"footnotes\"])\n",
    "    all_data.append(df)\n",
    "\n",
    "complete_data = pd.concat(all_data)\n",
    "\n",
    "df = complete_data.copy()\n",
    "df['date'] = pd.to_datetime(df['year'].astype(str) + df['period'].str.replace('M', ''), format='%Y%m')\n",
    "df['series id'] = df['series id'].astype(str) \n",
    "df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "df['footnotes'] = df['footnotes'].astype(str) \n",
    "df.drop(['year', 'period', 'footnotes'], axis=1, inplace=True)\n",
    "df.rename(columns={'series id': 'id'}, inplace=True)\n",
    "df = df[['id', 'date', 'value']]\n",
    "\n",
    "csv_path = os.path.join(folder_name, 'CPI_data.csv')\n",
    "df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"CPI_Data/CPI_data.csv\")\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MoM_change'] = df.groupby('id')['value'].transform(lambda x: (x - x.shift(-1)) / x.shift(-1))\n",
    "df['YoY_change'] = df.groupby('id')['value'].transform(lambda x: (x - x.shift(-12)) / x.shift(-12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_change(df, id1, id2, new_id, weight1, weight2, weight_total, operation):\n",
    "    \"\"\"\n",
    "    Calculate the weighted change between two series of data and return a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame containing the data.\n",
    "        id1 (str): The 'id' for the first series.\n",
    "        id2 (str): The 'id' for the second series.\n",
    "        new_id (str): The new 'id' for the result.\n",
    "        weight1 (float): The weight for the first series.\n",
    "        weight2 (float): The weight for the second series.\n",
    "        weight_total (float): The total weight for normalization.\n",
    "        operation (str): The operation to perform ('add' or 'subtract').\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing the result.\n",
    "    \"\"\"\n",
    "    series1 = df.loc[df['id'] == id1, ['MoM_change', 'YoY_change']].set_index(df.loc[df['id'] == id1, 'date']) * weight1\n",
    "    series2 = df.loc[df['id'] == id2, ['MoM_change', 'YoY_change']].set_index(df.loc[df['id'] == id2, 'date']) * weight2\n",
    "\n",
    "    if operation == 'add':\n",
    "        result = (series1 + series2) / weight_total\n",
    "    elif operation == 'subtract':\n",
    "        result = (series1 - series2) / weight_total\n",
    "    else:\n",
    "        raise ValueError(\"Operation must be 'add' or 'subtract'.\")\n",
    "\n",
    "    result = result.reset_index()\n",
    "    result['id'] = new_id\n",
    "    result['value'] = 0\n",
    "\n",
    "    result = result[['id', 'date', 'value', 'MoM_change', 'YoY_change']]\n",
    "    return result\n",
    "\n",
    "# Calculate 'SA_Food_Energy' and 'NSA_Food_Energy'\n",
    "df = pd.concat([\n",
    "    df,\n",
    "    calculate_weighted_change(df, 'SA_Food', 'SA_Energy', 'SA_Food_Energy', weight_map['Food'], weight_map['Energy'], weight_map['Food_Energy'], 'add'),\n",
    "    calculate_weighted_change(df, 'NSA_Food', 'NSA_Energy', 'NSA_Food_Energy', weight_map['Food'], weight_map['Energy'], weight_map['Food_Energy'], 'add')\n",
    "])\n",
    "\n",
    "# Calculate 'SA_Supercore' and 'NSA_Supercore'\n",
    "df = pd.concat([\n",
    "    df,\n",
    "    calculate_weighted_change(df, 'SA_Services_Less_Energy_Services', 'SA_Shelter', 'SA_Supercore', weight_map['Services_Less_Energy_Services'], weight_map['Shelter'], weight_map['Supercore'], 'subtract'),\n",
    "    calculate_weighted_change(df, 'NSA_Services_Less_Energy_Services', 'NSA_Shelter', 'NSA_Supercore', weight_map['Services_Less_Energy_Services'], weight_map['Shelter'], weight_map['Supercore'], 'subtract')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_map = {\n",
    "    'All_Items': (0, 'Headline', '', ''),\n",
    "    'Food_Energy': (1, 'Food + Energy', '', ''),\n",
    "    'Food': (2, '', 'Food', ''),\n",
    "    'Food_At_Home': (3, '', '', 'At home'),\n",
    "    'Food_Away_From_Home': (4, '', '', 'Away Home'),\n",
    "    'Energy': (5, '', 'Energy', ''),\n",
    "    'All_Items_Less_Food_Energy': (6, 'Core', '', ''),\n",
    "    'Commodities_Less_Food_Energy_Commodities': (7, '', 'Commodities', ''),\n",
    "    'Services_Less_Energy_Services': (8, '', 'Services', ''),\n",
    "    'Shelter': (9, '', '', 'Shelter'),\n",
    "    'Supercore': (10, '', '', 'Supercore')\n",
    "}\n",
    "\n",
    "ordered_categories = ['Headline', 'Food + Energy', 'Core']\n",
    "ordered_sub_categories_1 = ['Food', 'Energy', 'Commodities', 'Services']\n",
    "ordered_sub_categories_2 = ['At home', 'Away Home', 'Shelter', 'Supercore']\n",
    "\n",
    "for i in range(4):\n",
    "    if i in [0, 1]:\n",
    "        data = df[df['id'].str.startswith('NSA_')].copy()\n",
    "        prefix_length = 4\n",
    "    else:\n",
    "        data = df[df['id'].str.startswith('SA_')].copy() \n",
    "        prefix_length = 3\n",
    "\n",
    "    data.loc[:, 'id'] = data['id'].str[prefix_length:]\n",
    "\n",
    "    missing_ids = set(data['id']) - set(category_map.keys())\n",
    "    if missing_ids:\n",
    "        raise ValueError(f\"Missing IDs in category_map: {missing_ids}\")\n",
    "\n",
    "    data.loc[:, 'Month-Year'] = data['date'].dt.strftime('%b-%y')\n",
    "    order_cat = data['id'].apply(lambda x: category_map.get(x, (None, None, None, None)))\n",
    "    data.loc[:, 'Order'] = [item[0] for item in order_cat]\n",
    "    data.loc[:, 'Category'] = [item[1] for item in order_cat]\n",
    "    data.loc[:, 'Sub Category 1'] = [item[2] for item in order_cat]\n",
    "    data.loc[:, 'Sub Category 2'] = [item[3] for item in order_cat]\n",
    "    data.loc[:, 'Weight'] = data['id'].map(weight_map).fillna('Unknown')\n",
    "\n",
    "    if i in [0, 2]:\n",
    "        value_column = 'MoM_change'\n",
    "    else:\n",
    "        value_column = 'YoY_change'\n",
    "\n",
    "    data_pivot = data.pivot_table(\n",
    "        index=['Order', 'Category', 'Sub Category 1', 'Sub Category 2', 'Weight'],\n",
    "        columns='Month-Year',\n",
    "        values=value_column,\n",
    "        aggfunc='first'\n",
    "    )\n",
    "\n",
    "    data_pivot = data_pivot[sorted(data_pivot.columns, key=lambda x: pd.to_datetime(x, format='%b-%y'), reverse=True)]\n",
    "    data_pivot.columns.name = None\n",
    "    data_pivot.reset_index(inplace=True)\n",
    "    data_pivot.sort_values(by='Order', inplace=True)\n",
    "    data_pivot.drop(columns=['Order'], inplace=True)\n",
    "\n",
    "    if i == 0:\n",
    "        NSA_MoM_df = data_pivot\n",
    "    elif i == 1:\n",
    "        NSA_YoY_df = data_pivot\n",
    "    elif i == 2:\n",
    "        SA_MoM_df = data_pivot\n",
    "    else:\n",
    "        SA_YoY_df = data_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(folder_name, 'NSA_MoM_CPI_data.csv')\n",
    "NSA_MoM_df.to_csv(csv_path, index=False)\n",
    "\n",
    "csv_path = os.path.join(folder_name, 'NSA_YoY_CPI_data.csv')\n",
    "NSA_YoY_df.to_csv(csv_path, index=False)\n",
    "\n",
    "csv_path = os.path.join(folder_name, 'SA_MoM_CPI_data.csv')\n",
    "SA_MoM_df.to_csv(csv_path, index=False)\n",
    "\n",
    "csv_path = os.path.join(folder_name, 'SA_YoY_CPI_data.csv')\n",
    "SA_YoY_df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
